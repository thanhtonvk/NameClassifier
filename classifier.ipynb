{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import xgboost as xgb\n",
    "# import polars as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "  file = open(path)\n",
    "  data = file.read()\n",
    "  data_to_list_ = data.split(\"\\n\")\n",
    "  data_to_list = (list(set(data_to_list_)))\n",
    "  file.close()\n",
    "  return data_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tien_to_hau_to_1_word = read_file('./rule_files/tiento_hauto_1word.txt')\n",
    "tien_to_hau_to_mutil_word = read_file('./rule_files/tiento_hauto_multi-word.txt')\n",
    "\n",
    "ngoai_le_ca_nhan_mutil_word = read_file('./rule_files/ngoai_le_ca_nhan_mutil_word.txt')\n",
    "ngoai_le_ca_nhan_one_word = read_file('./rule_files/ngoai_le_ca_nhan_one_word.txt')\n",
    "\n",
    "special_name = read_file('./rule_files/special_person_name.txt')\n",
    "\n",
    "non_person = read_file('./rule_files/non_person')\n",
    "\n",
    "ngoai_le_one_word = ['codekhongsudung','code','inactive']\n",
    "ngoai_le_mutil_word = ['huy code','huy do trung so','huy do trung thong tin','trung code','code huy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# mutil word\n",
    "def loc_khtc2(text):\n",
    "    is_khtc = False\n",
    "    for word in tien_to_hau_to_mutil_word:\n",
    "        if word in text:\n",
    "            is_khtc = True\n",
    "            break\n",
    "    return is_khtc\n",
    "\n",
    "\n",
    "\n",
    "# once word\n",
    "def loc_khtc1(text):\n",
    "    words = text.split()\n",
    "    is_khtc = False\n",
    "    for word in words:\n",
    "        if word in tien_to_hau_to_1_word:\n",
    "            is_khtc = True\n",
    "            break\n",
    "    return is_khtc\n",
    "\n",
    "\n",
    "\n",
    "# loc ten ngoai le\n",
    "def loc_ngoai_le(text):\n",
    "    is_ngoaile = False\n",
    "    for word in non_person:\n",
    "        if word in text:\n",
    "            is_ngoaile = True\n",
    "            break\n",
    "    return is_ngoaile\n",
    "\n",
    "def loc_ngoai_le_one_word(text):\n",
    "    words = text.split()\n",
    "    is_ngoai_le = False\n",
    "    for word in words:\n",
    "        if word in ngoai_le_one_word:\n",
    "            is_ngoai_le = True\n",
    "            break\n",
    "    return is_ngoai_le\n",
    "def loc_ngoai_le_mutil_word(text):\n",
    "    is_ngoai_le = False\n",
    "    for word in ngoai_le_mutil_word:\n",
    "        if word in text:\n",
    "            is_ngoai_le = True\n",
    "            break\n",
    "    return is_ngoai_le\n",
    "\n",
    "\n",
    "# lọc ngoại lệ tên người\n",
    "def loc_ngoai_le_ca_nhan_one_word(text):\n",
    "    words = text.split()\n",
    "    is_ngoai_le = False\n",
    "    for word in words:\n",
    "        if word in ngoai_le_ca_nhan_one_word:\n",
    "            is_ngoai_le = True\n",
    "            break\n",
    "    return is_ngoai_le\n",
    "\n",
    "def loc_ngoai_le_ca_nhan_mutil_word(text):\n",
    "    is_ngoai_le = False\n",
    "    for word in ngoai_le_ca_nhan_mutil_word:\n",
    "        if word in text:\n",
    "            print(word)\n",
    "            is_ngoai_le = True\n",
    "            break\n",
    "    return is_ngoai_le\n",
    "        \n",
    "\n",
    "def has_special_char(s):\n",
    "    for c in s:\n",
    "        if not (c.isalpha() or c == ' '):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def has_one_word(s):\n",
    "    if \" \" not in s:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def has_is_full_number(s):\n",
    "    return s.isdigit()\n",
    "\n",
    "\n",
    "\n",
    "def check_person_name(s):\n",
    "    is_person_name = False\n",
    "    for name in special_name:\n",
    "        if s == name:\n",
    "            is_person_name = True\n",
    "    return is_person_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_train = 'data_generate/data_train_moredata5.csv'\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.load_model(\"models/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(real_x):\n",
    "\n",
    "    data_train = pd.read_csv(path_data_train)\n",
    "\n",
    "    x_train = data_train[\"name\"]\n",
    "\n",
    "    tfidf_vect_ngram_char = TfidfVectorizer(analyzer='char', max_features=30000, ngram_range=(2, 3))\n",
    "\n",
    "    tfidf_vect_ngram_char.fit(x_train)    \n",
    "\n",
    "    real_tfidf_ngram_char =  tfidf_vect_ngram_char.transform(real_x)\n",
    "\n",
    "    return real_tfidf_ngram_char\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_to_csv(id,real_x,file_path_export):\n",
    "\n",
    "    youden_threshold = 0.2\n",
    "\n",
    "    real_tfidf_ngram_char = preprocessing(real_x)\n",
    "\n",
    "    real_predictions_proba = model.predict_proba(real_tfidf_ngram_char)\n",
    "\n",
    "    real_predictions_proba_youden = (real_predictions_proba > youden_threshold).astype(int)\n",
    "\n",
    "    real_predictions_proba_youden = real_predictions_proba_youden[:, 1]\n",
    "\n",
    "    columns = [\"id\",\"name\",  \"ket qua du doan\"]\n",
    "\n",
    "    results = pd.DataFrame([id,real_x,  real_predictions_proba_youden])\n",
    "\n",
    "    results= results.transpose()\n",
    "\n",
    "    results.columns = columns\n",
    "\n",
    "    results.to_csv(file_path_export)\n",
    "\n",
    "    return file_path_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKH = 'MAKH'\n",
    "NAME = 'name'\n",
    "# Run model to classify\n",
    "def prediction(file_path):\n",
    "    # real_data = pd.read_csv(file_path,sep=\";\")        \n",
    "    # real_data= pd.read_csv(file_path)\n",
    "    real_data= pd.read_excel(file_path)\n",
    "    full_name =[]\n",
    "    ids = []\n",
    "    for i,id in enumerate(real_data[MAKH]):\n",
    "        tenkh= str(real_data[NAME][i])\n",
    "        #tenkh= real_data[NAME][i]\n",
    "        if has_special_char(tenkh):\n",
    "                real_data[NAME][i] = 'noname'\n",
    "                full_name.append(tenkh)\n",
    "                ids.append(id)\n",
    "        else:\n",
    "            try:\n",
    "                full_name.append(unidecode(tenkh).lower())\n",
    "                ids.append(id)\n",
    "            except:\n",
    "                real_data[NAME][i] = 'noname'\n",
    "                full_name.append(tenkh)\n",
    "                ids.append(id)\n",
    "    real_data = pd.DataFrame([ids,full_name])\n",
    "    real_data = real_data.transpose()\n",
    "    real_data.columns=  [MAKH,NAME]\n",
    "    real_x = real_data[NAME]\n",
    "    file_name_export = file_path.split('/')[-1].split('.')[0]\n",
    "    print(file_name_export)\n",
    "    file_path_export = f\"predict20M/{file_name_export}.csv\"\n",
    "    predict_to_csv(ids,real_x,file_path_export)\n",
    "    return file_path_export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book1\n"
     ]
    }
   ],
   "source": [
    "file_export = prediction('Book1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rule-based\n",
    "data =  pd.read_csv(file_export)\n",
    "new_pred = []\n",
    "for i in range(len(data)):\n",
    "    new_pred.append(data['ket qua du doan'][i])\n",
    "    ten_kh = str(data['name'][i])\n",
    "    if data['ket qua du doan'][i]== 0:\n",
    "        if loc_ngoai_le_ca_nhan_one_word(ten_kh) or loc_ngoai_le_ca_nhan_mutil_word(ten_kh):\n",
    "            new_pred[i] = 1\n",
    "        if check_person_name(ten_kh):\n",
    "            new_pred[i] = 1\n",
    "    if data['ket qua du doan'][i]==1:\n",
    "        if loc_khtc2(ten_kh) or loc_khtc1(ten_kh):\n",
    "            new_pred[i] = 0\n",
    "    if loc_ngoai_le(ten_kh.lower()) or loc_ngoai_le_one_word(ten_kh.lower()) or loc_ngoai_le_mutil_word(ten_kh.lower()):\n",
    "        new_pred[i] = 'ngoai le'\n",
    "    if has_is_full_number(ten_kh) or 'gmail' in ten_kh:\n",
    "        new_pred[i] = 'tap mo'\n",
    "predict = np.array(new_pred)\n",
    "data.insert(column='ket qua du doan new',value=predict,loc=4)\n",
    "data.to_csv(file_export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

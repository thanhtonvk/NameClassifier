{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import xgboost as xgb\n",
    "# import polars as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "  file = open(path)\n",
    "  data = file.read()\n",
    "  data_to_list_ = data.split(\"\\n\")\n",
    "  data_to_list = (list(set(data_to_list_)))\n",
    "  file.close()\n",
    "  return data_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tien_to_hau_to_1_word = read_file('./rule_files/tiento_hauto_1word.txt')\n",
    "tien_to_hau_to_mutil_word = read_file('./rule_files/tiento_hauto_multi-word.txt')\n",
    "\n",
    "ngoai_le_ca_nhan_mutil_word = read_file('./rule_files/ngoai_le_ca_nhan_mutil_word.txt')\n",
    "ngoai_le_ca_nhan_one_word = read_file('./rule_files/ngoai_le_ca_nhan_one_word.txt')\n",
    "\n",
    "special_name = read_file('./rule_files/special_person_name.txt')\n",
    "non_person = read_file('./rule_files/non_person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngoai_le_one_word = ['codekhongsudung','code','inactive', \"notuser\", \"notuserkhongdung\", \"notused\",\"khongsudung\",\"test\",\"notuse\",\"nouser\",\n",
    "                    \"noname\", \"huy+cmt\", \"huycode\", \"huydotrungcode\", \"huy-\", \"-huy\"]\n",
    "ngoai_le_mutil_word = ['huy code','huy do trung so', 'huy do trung code','huy do trung thong tin','trung code','code huy', \"not used\", \"not use\",\n",
    "                       \"khong sudung\",\"khongsu dung\", \"huy +\",\"- huy\"\n",
    "                      \"no name\", \"khong su dung\", \"khong dang dung\", \"huy co do trung\", \"huy do kh 2\", \"huy do trung cmnd\", \"huy -\", \"golive payroll\",\"golive khcn\",\"not be used\",\n",
    "                      ]\n",
    "list_tap_mo_multi_word = [\"chua xac minh\", \"chuyen sang code\", \"code online\", \"code trung\",\"ho va ten:\", \"upload cmnd\"]\n",
    "list_tap_mo_one_word = [\".com\", \"gmail\", \"khcn-vat-out\", \"gmail.com\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xyz9876\n",
      "12kl34\n"
     ]
    }
   ],
   "source": [
    "string_list = [\"abc123\", \"xyz9876\", \"12kl34\", \"abcd\", \"1234567\"]\n",
    "\n",
    "for s in string_list:\n",
    "    if any(c.isalpha() for c in s) and any(c.isdigit() for c in s) and sum(c.isdigit() for c in s) >= 4:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_check = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutil word\n",
    "def loc_khtc2(text):\n",
    "    is_khtc = False\n",
    "    for word in tien_to_hau_to_mutil_word:\n",
    "        if word in text:\n",
    "  \n",
    "            is_khtc = True\n",
    "            break\n",
    "    return is_khtc\n",
    "\n",
    "# one word\n",
    "def loc_khtc1(text):\n",
    "    words = text.split()\n",
    "    is_khtc = False\n",
    "    for word in words:\n",
    "        if word in tien_to_hau_to_1_word:\n",
    "       \n",
    "            is_khtc = True\n",
    "            break\n",
    "    return is_khtc\n",
    "\n",
    "# loc ten ngoai le\n",
    "def loc_ngoai_le_one_word(text):\n",
    "    words = text.split()\n",
    "    is_ngoai_le = False\n",
    "    for word in words:\n",
    "        if word in ngoai_le_one_word:\n",
    "            is_ngoai_le = True\n",
    "            break\n",
    "    return is_ngoai_le\n",
    "def loc_ngoai_le_mutil_word(text):\n",
    "    is_ngoai_le = False\n",
    "    for word in ngoai_le_mutil_word:\n",
    "        if word in text:\n",
    "            is_ngoai_le = True\n",
    "            break\n",
    "    return is_ngoai_le\n",
    "\n",
    "\n",
    "# lọc ngoại lệ tên người\n",
    "def loc_ngoai_le_ca_nhan_one_word(text):\n",
    "    words = text.split()\n",
    "    is_ngoai_le = False\n",
    "    for word in words:\n",
    "        if word in ngoai_le_ca_nhan_one_word:\n",
    "            is_ngoai_le = True\n",
    "            break\n",
    "    return is_ngoai_le\n",
    "\n",
    "def loc_ngoai_le_ca_nhan_mutil_word(text):\n",
    "    is_ngoai_le = False\n",
    "    for word in ngoai_le_ca_nhan_mutil_word:\n",
    "        if word in text:\n",
    "     \n",
    "            is_ngoai_le = True\n",
    "            break\n",
    "    return is_ngoai_le\n",
    "        \n",
    "\n",
    "def has_special_char(s):\n",
    "    for c in s:\n",
    "        if not (c.isalpha() or c == ' '):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def has_one_word(s):\n",
    "    if \" \" not in s:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def has_is_full_number(s):\n",
    "    return s.isdigit()\n",
    "\n",
    "def has_over_2number(s):\n",
    "    is_over_2number = False\n",
    "    if any(c.isalpha() for c in s) and any(c.isdigit() for c in s) and sum(c.isdigit() for c in s) >= 2:\n",
    "        is_over_2number = True\n",
    "    return is_over_2number\n",
    "\n",
    "def check_person_name(s):\n",
    "    is_person_name = False\n",
    "    for name in special_name:\n",
    "        if s == name:\n",
    "            is_person_name = True\n",
    "    return is_person_name\n",
    "\n",
    "# loc tap mo\n",
    "def loc_tapmo_one_word(text):\n",
    "    words = text.split()\n",
    "    is_tapmo = False\n",
    "    for word in words:\n",
    "        if word in list_tap_mo_one_word:\n",
    "            is_tapmo = True\n",
    "            break\n",
    "    return is_tapmo\n",
    "def loc_tapmo_mutil_word(text):\n",
    "    is_tapmo = False\n",
    "    for word in list_tap_mo_multi_word:\n",
    "        if word in text:\n",
    "            is_tapmo = True\n",
    "            break\n",
    "    return is_tapmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tap mo\n"
     ]
    }
   ],
   "source": [
    "ten_kh = \"hainp gmail.com\"\n",
    "if has_over_2number(ten_kh) or has_is_full_number(ten_kh) or loc_tapmo_one_word(ten_kh) or loc_tapmo_mutil_word(ten_kh):\n",
    "    print(\"Tap mo\")\n",
    "else: print(\"Khong phai tap mo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_train = 'data_generate/data_train_moredata5.csv'\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model(\"models/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(real_x):\n",
    "\n",
    "    data_train = pd.read_csv(path_data_train)\n",
    "\n",
    "    x_train = data_train[\"name\"]\n",
    "\n",
    "    tfidf_vect_ngram_char = TfidfVectorizer(analyzer='char', max_features=30000, ngram_range=(2, 3))\n",
    "\n",
    "    tfidf_vect_ngram_char.fit(x_train)    \n",
    "\n",
    "    real_tfidf_ngram_char =  tfidf_vect_ngram_char.transform(real_x)\n",
    "\n",
    "    return real_tfidf_ngram_char\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict_to_csv(id,real_x,file_path_export):\n",
    "\n",
    "    youden_threshold = 0.2\n",
    "\n",
    "    real_tfidf_ngram_char = preprocessing(real_x)\n",
    "\n",
    "    real_predictions_proba = model.predict_proba(real_tfidf_ngram_char)\n",
    "\n",
    "    real_predictions_proba_youden = (real_predictions_proba > youden_threshold).astype(int)\n",
    "\n",
    "    real_predictions_proba_youden = real_predictions_proba_youden[:, 1]\n",
    "\n",
    "    columns = [\"id\",\"name\",  \"ket qua du doan\"]\n",
    "\n",
    "    results = pd.DataFrame([id,real_x,  real_predictions_proba_youden])\n",
    "\n",
    "    results= results.transpose()\n",
    "\n",
    "    results.columns = columns\n",
    "\n",
    "    results.to_csv(file_path_export)\n",
    "\n",
    "    return file_path_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKH = 'MAKH'\n",
    "NAME = 'name'\n",
    "# Run model to classify\n",
    "def prediction(file_path):\n",
    "    # real_data = pd.read_csv(file_path,sep=\";\")        \n",
    "    # real_data= pd.read_csv(file_path)\n",
    "    real_data= pd.read_excel(file_path)\n",
    "    full_name =[]\n",
    "    ids = []\n",
    "    for i,id in enumerate(real_data[MAKH]):\n",
    "        tenkh= str(real_data[NAME][i])\n",
    "        #tenkh= real_data[NAME][i]\n",
    "        if has_special_char(tenkh):\n",
    "                real_data[NAME][i] = 'noname'\n",
    "                full_name.append(tenkh)\n",
    "                ids.append(id)\n",
    "        else:\n",
    "            try:\n",
    "                full_name.append(unidecode(tenkh).lower())\n",
    "                ids.append(id)\n",
    "            except:\n",
    "                real_data[NAME][i] = 'noname'\n",
    "                full_name.append(tenkh)\n",
    "                ids.append(id)\n",
    "    real_data = pd.DataFrame([ids,full_name])\n",
    "    real_data = real_data.transpose()\n",
    "    real_data.columns=  [MAKH,NAME]\n",
    "    real_x = real_data[NAME]\n",
    "    file_name_export = file_path.split('/')[-1].split('.')[0]\n",
    "    print(file_name_export)\n",
    "    file_path_export = f\"predict20M/{file_name_export}.csv\"\n",
    "    predict_to_csv(ids,real_x,file_path_export)\n",
    "    return file_path_export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheet5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20436\\2932368563.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  real_data[NAME][i] = 'noname'\n"
     ]
    }
   ],
   "source": [
    "file_export = prediction('sheet5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rule-based\n",
    "data =  pd.read_csv(file_export)\n",
    "new_pred = []\n",
    "for i in range(len(data)):\n",
    "    new_pred.append(data['ket qua du doan'][i])\n",
    "    ten_kh = str(data['name'][i])\n",
    "    if data['ket qua du doan'][i]== 0:\n",
    "        if loc_ngoai_le_ca_nhan_one_word(ten_kh) or loc_ngoai_le_ca_nhan_mutil_word(ten_kh):\n",
    "            new_pred[i] = 1\n",
    "        if check_person_name(ten_kh):\n",
    "            new_pred[i] = 1\n",
    "    if data['ket qua du doan'][i]==1:\n",
    "        if loc_khtc2(ten_kh) or loc_khtc1(ten_kh):\n",
    "            new_pred[i] = 0\n",
    "    if loc_ngoai_le_one_word(ten_kh.lower()) or loc_ngoai_le_mutil_word(ten_kh.lower()):\n",
    "        new_pred[i] = 'ngoai le'\n",
    "    if has_over_2number(ten_kh) or has_is_full_number(ten_kh) or loc_tapmo_one_word(ten_kh) or loc_tapmo_mutil_word(ten_kh):\n",
    "        new_pred[i] = 'tap mo'\n",
    "predict = np.array(new_pred)\n",
    "data.insert(column='ket qua du doan new',value=predict,loc=4)\n",
    "data.to_csv(file_export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
